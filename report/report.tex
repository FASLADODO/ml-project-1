\documentclass{article} % For LaTeX2e
% We will use NIPS submission format
\usepackage{nips13submit_e,times}
% for hyperlinks
\usepackage{hyperref}
\usepackage{url}
% For figures
\usepackage{graphicx}
\usepackage{subfigure}
% math packages
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsopn}
\usepackage{ifthen}
\usepackage{natbib}

\title{Machine Learning Project I by Group KATHMANDU}

\author{
Jade Copet\\
EPFL \\
\texttt{jade.copet@epfl.com} \\
\And
Merlin Nimier David\\
EPFL \\
\texttt{merlin.nimier-david@epfl.com} \\
\And
Krishna Raj Sapkota\\
EPFL \\
\texttt{krishna.sapkota@epfl.com} \\
}

\nipsfinalcopy

\begin{document}

\maketitle

\begin{abstract}
  In this report, we summarize our findings for the project-I. We analyzed two datasets, regression (D1) and classification (D2).
\end{abstract}

\section{Regression dataset (D1) description}
  Our training data consists of output variables $\mathbf{y}$ and input variables $\mathbf{X}$. We have $N = 1400$ data examples. Each input vector $\mathbf{x}_n$ is of dimensionality $D = 44$. Out of these 44 features, 35 are real-valued while 4 variables are binary and 5 variables are categorical, 4 of them with 4 categories and 1 with 3 categories.

  We also have test data where we do not observe $\mathbf{y}$. We have $N = 600$ test examples. Our goal is to produce predictions for test examples, as well as an approximation of the test error.

\section{Data visualization and cleaning}
  - y distribution (histogram) notice 2 different shapes (can't be outliers)\\
  - (Not rank deficient)\\
  - Normalization\\
  - Model separation : with the X against Y plots with data separated wrt X35 value. Explain why it should not be considered as outliers \\
  - Correlations : results in a table ? we might be able to remove some features (go to regressionFitSelectedFeatures)\\
  - Dummy variables encoding

\section{Regression fit}
  - one-variable model VS least squares VS ridge regression\\
  - RMSE errors\\
  - Discussion on overfitting, proportion selection, validation...

\section{Feature transformations}
  - use ridge regression because of the resulting matrix singularity\\
  - compare different polynomial degrees (box plots, rmse values), selection and validation

\section{Predictions}

\section{Summary}

\subsubsection*{Acknowledgments}

\subsubsection*{References}

\end{document}
